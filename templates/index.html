<!DOCTYPE html>
<html>
  <head>
    <title>Voice Recorder</title>
  </head>
  <body>
    <h2>ğŸ¤ Record Your Message</h2>
    <button id="recordBtn">ğŸ™ï¸ Start Recording</button>
    <button id="stopBtn" disabled>ğŸ›‘ Stop</button>
    <p id="status"></p>
    <p><strong>Transcription:</strong> <span id="resultText"></span></p>

    <script>
      let audioContext;
      let mediaRecorder;
      let audioData = [];

      const recordBtn = document.getElementById("recordBtn");
      const stopBtn = document.getElementById("stopBtn");
      const statusText = document.getElementById("status");
      const resultText = document.getElementById("resultText");

      recordBtn.onclick = async () => {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const input = audioContext.createMediaStreamSource(stream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);

        input.connect(processor);
        processor.connect(audioContext.destination);

        audioData = [];

        processor.onaudioprocess = (e) => {
          const channelData = e.inputBuffer.getChannelData(0);
          audioData.push(new Float32Array(channelData));
        };

        mediaRecorder = { stream, processor };
        statusText.innerText = "ğŸ™ï¸ Recording...";
        recordBtn.disabled = true;
        stopBtn.disabled = false;
      };

      stopBtn.onclick = async () => {
        const { stream, processor } = mediaRecorder;
        processor.disconnect();
        stream.getTracks().forEach((track) => track.stop());

        const wavBlob = encodeWAV(audioData, audioContext.sampleRate);
        const formData = new FormData();
        formData.append("file", wavBlob, "voice.wav");

        statusText.innerText = "â³ Uploading and transcribing...";
        recordBtn.disabled = false;
        stopBtn.disabled = true;

        const response = await fetch("/process_timesheet", {
          method: "POST",
          body: formData,
        });

        const data = await response.json();
        if (data) {
          // resultText.innerText = data.text;
          statusText.innerText = "âœ… Transcribed successfully.";
        } else {
          statusText.innerText = "âŒ Transcription failed.";
        }
      };

      function encodeWAV(audioData, sampleRate) {
        const flat = audioData.reduce((acc, val) => {
          const tmp = new Float32Array(acc.length + val.length);
          tmp.set(acc);
          tmp.set(val, acc.length);
          return tmp;
        }, new Float32Array());

        const buffer = new ArrayBuffer(44 + flat.length * 2);
        const view = new DataView(buffer);

        function writeString(view, offset, str) {
          for (let i = 0; i < str.length; i++) {
            view.setUint8(offset + i, str.charCodeAt(i));
          }
        }

        writeString(view, 0, "RIFF");
        view.setUint32(4, 36 + flat.length * 2, true);
        writeString(view, 8, "WAVE");
        writeString(view, 12, "fmt ");
        view.setUint32(16, 16, true); // Subchunk1Size
        view.setUint16(20, 1, true); // AudioFormat
        view.setUint16(22, 1, true); // NumChannels
        view.setUint32(24, sampleRate, true); // SampleRate
        view.setUint32(28, sampleRate * 2, true); // ByteRate
        view.setUint16(32, 2, true); // BlockAlign
        view.setUint16(34, 16, true); // BitsPerSample
        writeString(view, 36, "data");
        view.setUint32(40, flat.length * 2, true);

        let offset = 44;
        for (let i = 0; i < flat.length; i++, offset += 2) {
          const s = Math.max(-1, Math.min(1, flat[i]));
          view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
        }

        return new Blob([view], { type: "audio/wav" });
      }
    </script>
  </body>
</html>
